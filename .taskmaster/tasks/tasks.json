{
  "format_version": "1.0",
  "created_date": "2025-06-17",
  "last_modified": "2025-06-17",
  "total_tasks": 8,
  "tasks": [
    {
      "id": 1,
      "title": "Set up Python project structure and FastAPI backend",
      "description": "Create the basic Python project structure with FastAPI, implement health check endpoints, and set up the foundational architecture for the Hungarian Legal AI system.",
      "status": "todo",
      "priority": "high",
      "complexity": 5,
      "created_date": "2025-06-17",
      "tags": ["backend", "setup", "fastapi"],
      "implementation_plan": "1. Create src/ directory structure\n2. Set up FastAPI application with main.py\n3. Create config/ directory for configuration management\n4. Add health check endpoints\n5. Set up basic logging",
      "acceptance_criteria": [
        "FastAPI server starts without errors",
        "Health check endpoint returns 200 status",
        "Basic project structure follows Python best practices",
        "Configuration management is properly set up"
      ],
      "dependencies": [],
      "estimated_hours": 4
    },
    {
      "id": 2,
      "title": "Implement NJT.hu crawler for legal documents",
      "description": "Develop a web crawler to collect Hungarian legal documents from njt.hu using ELI (European Legislation Identifier) standards for programmatic URL generation.",
      "status": "todo",
      "priority": "high",
      "complexity": 8,
      "created_date": "2025-06-17",
      "tags": ["crawler", "data-collection", "legal"],
      "implementation_plan": "1. Research njt.hu structure and ELI standards\n2. Create base crawler class\n3. Implement ELI-based URL generation\n4. Add rate limiting and politeness policies\n5. Handle different document types\n6. Add error handling and retry logic",
      "acceptance_criteria": [
        "Crawler can successfully fetch legal documents from njt.hu",
        "ELI standard is properly implemented",
        "Rate limiting prevents server overload",
        "Error handling covers common failure scenarios"
      ],
      "dependencies": [1],
      "estimated_hours": 12
    },
    {
      "id": 3,
      "title": "Set up PostgreSQL and MongoDB databases",
      "description": "Configure and set up the database infrastructure including PostgreSQL for structured data and MongoDB for document storage.",
      "status": "todo",
      "priority": "high",
      "complexity": 6,
      "created_date": "2025-06-17",
      "tags": ["database", "postgresql", "mongodb"],
      "implementation_plan": "1. Set up PostgreSQL database schema\n2. Configure MongoDB for document storage\n3. Create database connection managers\n4. Implement basic CRUD operations\n5. Add database migrations system",
      "acceptance_criteria": [
        "PostgreSQL database is properly configured",
        "MongoDB connection is established",
        "Database schemas are created",
        "Connection managers handle errors gracefully"
      ],
      "dependencies": [1],
      "estimated_hours": 6
    },
    {
      "id": 4,
      "title": "Implement vector database for semantic search",
      "description": "Set up Weaviate or Qdrant for vector storage and semantic search capabilities for legal documents.",
      "status": "todo",
      "priority": "medium",
      "complexity": 7,
      "created_date": "2025-06-17",
      "tags": ["vector-db", "semantic-search", "embeddings"],
      "implementation_plan": "1. Choose between Weaviate and Qdrant\n2. Set up vector database instance\n3. Create embedding generation pipeline\n4. Implement vector search functionality\n5. Add semantic similarity scoring",
      "acceptance_criteria": [
        "Vector database is operational",
        "Embeddings can be generated and stored",
        "Semantic search returns relevant results",
        "Performance meets requirements"
      ],
      "dependencies": [1, 3],
      "estimated_hours": 10
    },
    {
      "id": 5,
      "title": "Create legal document chunking and preprocessing",
      "description": "Implement intelligent chunking algorithms for legal documents that respect legal structure (paragraphs, sections, articles).",
      "status": "todo",
      "priority": "medium",
      "complexity": 6,
      "created_date": "2025-06-17",
      "tags": ["nlp", "preprocessing", "chunking"],
      "implementation_plan": "1. Analyze legal document structure\n2. Implement paragraph-based chunking\n3. Add section and article awareness\n4. Create metadata extraction\n5. Handle different document formats",
      "acceptance_criteria": [
        "Legal documents are chunked intelligently",
        "Legal structure is preserved",
        "Metadata is properly extracted",
        "Different document formats are supported"
      ],
      "dependencies": [2, 3],
      "estimated_hours": 8
    },
    {
      "id": 6,
      "title": "Implement basic search agent",
      "description": "Create the first agent that can perform basic semantic and lexical searches across the legal document corpus.",
      "status": "todo",
      "priority": "medium",
      "complexity": 5,
      "created_date": "2025-06-17",
      "tags": ["agent", "search", "nlp"],
      "implementation_plan": "1. Create base agent class\n2. Implement semantic search logic\n3. Add lexical search capabilities\n4. Combine and rank results\n5. Add query understanding",
      "acceptance_criteria": [
        "Agent can perform semantic searches",
        "Lexical search functionality works",
        "Results are properly ranked",
        "Query understanding is implemented"
      ],
      "dependencies": [4, 5],
      "estimated_hours": 6
    },
    {
      "id": 7,
      "title": "Set up Claude API integration",
      "description": "Integrate with Claude API for natural language processing tasks and legal document analysis.",
      "status": "todo",
      "priority": "high",
      "complexity": 4,
      "created_date": "2025-06-17",
      "tags": ["api", "claude", "integration"],
      "implementation_plan": "1. Set up Claude API client\n2. Implement retry logic and error handling\n3. Create prompt templates for legal tasks\n4. Add token usage tracking\n5. Implement rate limiting",
      "acceptance_criteria": [
        "Claude API integration works correctly",
        "Error handling is robust",
        "Token usage is tracked",
        "Rate limiting prevents API abuse"
      ],
      "dependencies": [1],
      "estimated_hours": 4
    },
    {
      "id": 8,
      "title": "Create basic web interface for testing",
      "description": "Develop a simple web interface to test the legal document search and analysis functionality.",
      "status": "todo",
      "priority": "low",
      "complexity": 5,
      "created_date": "2025-06-17",
      "tags": ["frontend", "testing", "ui"],
      "implementation_plan": "1. Create basic HTML/CSS interface\n2. Add search functionality\n3. Display search results\n4. Add basic document viewer\n5. Implement responsive design",
      "acceptance_criteria": [
        "Web interface is functional",
        "Search works from the UI",
        "Results are properly displayed",
        "Interface is responsive"
      ],
      "dependencies": [6, 7],
      "estimated_hours": 6
    }
  ]
} 